{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset shape: \n",
      "(41188, 21)\n"
     ]
    }
   ],
   "source": [
    "# Supress unnecessary warnings so that presentation looks clean\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import needed packages needed for EDA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Print all rows and columns. Dont hide any\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "bankingcalldata = pd.read_csv('data/bank-additional-full.csv', sep=';')\n",
    "\n",
    "print('Full dataset shape: ')\n",
    "print(bankingcalldata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  duration  campaign  pdays  previous     poutcome  \\\n",
       "0   may         mon       261         1    999         0  nonexistent   \n",
       "1   may         mon       149         1    999         0  nonexistent   \n",
       "2   may         mon       226         1    999         0  nonexistent   \n",
       "3   may         mon       151         1    999         0  nonexistent   \n",
       "4   may         mon       307         1    999         0  nonexistent   \n",
       "\n",
       "   emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "1           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "2           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "3           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "4           1.1          93.994          -36.4      4.857       5191.0  no  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bankingcalldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no missing values in the dataset.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, average_precision_score, recall_score, confusion_matrix\n",
    "from scipy.stats import skew, boxcox\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "\n",
    "import itertools\n",
    "\n",
    "if bankingcalldata.isnull().values.any() == True:\n",
    "    print('There are missing values in the dataset.')\n",
    "else:\n",
    "    print('There are no missing values in the dataset.')\n",
    "\n",
    "columns = list(bankingcalldata.columns)\n",
    "    \n",
    "for column in columns:\n",
    "    if bankingcalldata[column].isnull().values.any() == True:\n",
    "        print('There are missing values in the column ' + column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical columns..\n",
      "Checking datatypes..\n",
      "All columns are encoded.\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ONE_HOT = False\n",
    "\n",
    "#Variable to hold the list of variables for an attribute in the train and test data\n",
    "labels = []\n",
    "to_be_encoded = ['job','marital','education','default','housing','loan','contact','month','day_of_week','previous',\n",
    "                 'poutcome']\n",
    "\n",
    "print('Encoding categorical columns..')\n",
    "\n",
    "for i in bankingcalldata.columns.values:\n",
    "    if bankingcalldata[i].dtype == object:\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        bankingcalldata[i] = lbl.fit_transform(bankingcalldata[i])\n",
    "\n",
    "for i in range(len(to_be_encoded)):\n",
    "    labels.append(list(bankingcalldata[to_be_encoded[i]].unique()))\n",
    "    \n",
    "#One hot encode all categorical attributes\n",
    "cats = []\n",
    "encoded_data = bankingcalldata.drop('y', axis=1)\n",
    "        \n",
    "#One hot encode\n",
    "if ONE_HOT:\n",
    "    for i in range(len(to_be_encoded)):\n",
    "        feature = encoded_data[to_be_encoded[i]]\n",
    "        feature = feature.reshape(encoded_data.shape[0], 1)\n",
    "        onehot_encoder = OneHotEncoder(sparse=False,n_values=len(labels[i]))\n",
    "        feature = onehot_encoder.fit_transform(feature)\n",
    "        cats.append(feature)\n",
    "\n",
    "    # Make a 2D array from a list of 1D arrays\n",
    "    encoded_cats = np.column_stack(cats)\n",
    "\n",
    "    # Print the shape of the encoded data\n",
    "    print(encoded_cats.shape)\n",
    "\n",
    "    #Concatenate encoded attributes with continuous attributes\n",
    "    bankingcalldata_encoded = encoded_data.drop(to_be_encoded, axis=1)\n",
    "    bankingcalldata_encoded = np.concatenate((encoded_cats,bankingcalldata_encoded),axis=1)\n",
    "    \n",
    "    bankingcalldata_encoded = pd.DataFrame(bankingcalldata_encoded)\n",
    "    \n",
    "    print('Checking datatypes..')\n",
    "    tmp = 0\n",
    "    for i in bankingcalldata_encoded.columns.values:\n",
    "        if bankingcalldata_encoded[i].dtype == object:\n",
    "            tmp = tmp + 1\n",
    "    if tmp == 0:\n",
    "        print('All columns are encoded.')\n",
    "    else:\n",
    "        print('Not all columns are encoded')\n",
    "    \n",
    "else:\n",
    "    print('Checking datatypes..')\n",
    "    tmp = 0\n",
    "    for i in bankingcalldata.columns.values:\n",
    "        if bankingcalldata[i].dtype == object:\n",
    "            tmp = tmp + 1\n",
    "    if tmp == 0:\n",
    "        print('All columns are encoded.')\n",
    "    else:\n",
    "        print('Not all columns are encoded')\n",
    "\n",
    "print('Finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24712, 20)\n",
      "(16476, 20)\n",
      "(24712,)\n",
      "(16476,)\n",
      "0    36548\n",
      "1     4640\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if ONE_HOT:\n",
    "    X_full = bankingcalldata_encoded\n",
    "else:\n",
    "    X_full = bankingcalldata.drop('y', axis=1) \n",
    "    \n",
    "y_full = bankingcalldata['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.40, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(y_full.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(array):\n",
    "    TN = array[0,0]\n",
    "    TP = array[1,1]\n",
    "    FN = array[1,0]\n",
    "    FP = array[0,1]\n",
    "    \n",
    "    return((TP + TN) / (TN + TP + FN + FP))\n",
    "def precision(array):\n",
    "    TN = array[0,0]\n",
    "    TP = array[1,1]\n",
    "    FN = array[1,0]\n",
    "    FP = array[0,1]\n",
    "    \n",
    "    return(TP / (TP + FP))\n",
    "def recall(array):\n",
    "    TN = array[0,0]\n",
    "    TP = array[1,1]\n",
    "    FN = array[1,0]\n",
    "    FP = array[0,1]\n",
    "    \n",
    "    return(TP / (TP + FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold 1\n",
      "\n",
      " train-Accuracy: 0.904991\n",
      " train-Precision: 0.703399\n",
      " train-Recall: 0.272329\n",
      "\n",
      " eval-Accuracy: 0.906553\n",
      " eval-Precision: 0.700000\n",
      " eval-Recall: 0.301075\n",
      "\n",
      " Fold 2\n",
      "\n",
      " train-Accuracy: 0.905351\n",
      " train-Precision: 0.702513\n",
      " train-Recall: 0.278708\n",
      "\n",
      " eval-Accuracy: 0.904935\n",
      " eval-Precision: 0.720000\n",
      " eval-Recall: 0.258065\n",
      "\n",
      " Fold 3\n",
      "\n",
      " train-Accuracy: 0.905081\n",
      " train-Precision: 0.699899\n",
      " train-Recall: 0.277113\n",
      "\n",
      " eval-Accuracy: 0.903317\n",
      " eval-Precision: 0.717391\n",
      " eval-Recall: 0.236559\n",
      "\n",
      " Fold 4\n",
      "\n",
      " train-Accuracy: 0.905306\n",
      " train-Precision: 0.700599\n",
      " train-Recall: 0.279904\n",
      "\n",
      " eval-Accuracy: 0.902508\n",
      " eval-Precision: 0.686275\n",
      " eval-Recall: 0.250896\n",
      "\n",
      " Fold 5\n",
      "\n",
      " train-Accuracy: 0.904182\n",
      " train-Precision: 0.693333\n",
      " train-Recall: 0.269537\n",
      "\n",
      " eval-Accuracy: 0.911812\n",
      " eval-Precision: 0.774775\n",
      " eval-Recall: 0.308244\n",
      "\n",
      " Fold 6\n",
      "\n",
      " train-Accuracy: 0.904905\n",
      " train-Precision: 0.699898\n",
      " train-Recall: 0.274322\n",
      "\n",
      " eval-Accuracy: 0.904087\n",
      " eval-Precision: 0.698113\n",
      " eval-Recall: 0.265233\n",
      "\n",
      " Fold 7\n",
      "\n",
      " train-Accuracy: 0.905445\n",
      " train-Precision: 0.704339\n",
      " train-Recall: 0.278309\n",
      "\n",
      " eval-Accuracy: 0.903683\n",
      " eval-Precision: 0.681416\n",
      " eval-Recall: 0.275986\n",
      "\n",
      " Fold 8\n",
      "\n",
      " train-Accuracy: 0.904100\n",
      " train-Precision: 0.694617\n",
      " train-Recall: 0.267437\n",
      "\n",
      " eval-Accuracy: 0.913765\n",
      " eval-Precision: 0.764228\n",
      " eval-Recall: 0.338129\n",
      "\n",
      " Fold 9\n",
      "\n",
      " train-Accuracy: 0.905989\n",
      " train-Precision: 0.709000\n",
      " train-Recall: 0.282583\n",
      "\n",
      " eval-Accuracy: 0.896761\n",
      " eval-Precision: 0.611650\n",
      " eval-Recall: 0.226619\n",
      "\n",
      " Fold 10\n",
      "\n",
      " train-Accuracy: 0.905224\n",
      " train-Precision: 0.704801\n",
      " train-Recall: 0.275010\n",
      "\n",
      " eval-Accuracy: 0.902834\n",
      " eval-Precision: 0.650794\n",
      " eval-Recall: 0.294964\n"
     ]
    }
   ],
   "source": [
    "#Import the library\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "def ridge_model(alpha, X, y):\n",
    "    \n",
    "    ridge_model = RidgeClassifier(alpha, fit_intercept= True, normalize=True)\n",
    "    ridge_model.fit(X, y)\n",
    "    return ridge_model\n",
    "\n",
    "n_folds = 10\n",
    "alpha = 0.1\n",
    "i = 0\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_folds, random_state=123, shuffle=True)\n",
    "\n",
    "for (train_index, test_index) in skf.split(X_train, y_train):\n",
    "    # cross-validation randomly splits train data into train and validation data\n",
    "    print('\\n Fold %d' % (i + 1))\n",
    "    \n",
    "    X_train_cv, X_val_cv = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_cv, y_val_cv = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    " \n",
    "    # declare your model\n",
    "    model = ridge_model(alpha, X_train_cv, y_train_cv)\n",
    "    \n",
    "    # predict train and validation set accuracy and get eval metrics\n",
    "    scores_cv = model.predict(X_train_cv)\n",
    "    scores_val = model.predict(X_val_cv)\n",
    "\n",
    "    train_confusion_matrix = confusion_matrix(y_train_cv, np.around(scores_cv).astype(int))\n",
    "    val_confusion_matrix = confusion_matrix(y_val_cv, np.around(scores_val).astype(int))\n",
    "\n",
    "    train_pc = accuracy(train_confusion_matrix)\n",
    "    train_pp = precision(train_confusion_matrix)\n",
    "    train_re = recall(train_confusion_matrix)\n",
    "    print('\\n train-Accuracy: %.6f' % train_pc)\n",
    "    print(' train-Precision: %.6f' % train_pp)\n",
    "    print(' train-Recall: %.6f' % train_re)\n",
    "    \n",
    "    eval_pc = accuracy(val_confusion_matrix)\n",
    "    eval_pp = precision(val_confusion_matrix)\n",
    "    eval_re = recall(val_confusion_matrix)\n",
    "    print('\\n eval-Accuracy: %.6f' % eval_pc)\n",
    "    print(' eval-Precision: %.6f' % eval_pp)\n",
    "    print(' eval-Recall: %.6f' % eval_re)\n",
    "\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Ridge full-Accuracy: 0.905118\n",
      " Ridge full-Precision: 0.696141\n",
      " Ridge full-Recall: 0.279957\n"
     ]
    }
   ],
   "source": [
    "# divide predictions and CV-sum by number of folds to get mean of all folds\n",
    "final_train_pred_ridge = model.predict(X_train)\n",
    "final_test_pred_ridge = model.predict(X_test)\n",
    "final_full_pred_ridge = model.predict(X_full)\n",
    "\n",
    "train_confusion_matrix_ridge = confusion_matrix(y_train, np.around(final_train_pred_ridge).astype(int))\n",
    "test_confusion_matrix_ridge = confusion_matrix(y_test, np.around(final_test_pred_ridge).astype(int))\n",
    "full_confusion_matrix_ridge = confusion_matrix(y_full, np.around(final_full_pred_ridge).astype(int))\n",
    "\n",
    "final_train_accuracy_ridge = accuracy(train_confusion_matrix_ridge)\n",
    "final_train_precision_ridge = precision(train_confusion_matrix_ridge)\n",
    "final_train_recall_ridge = recall(train_confusion_matrix_ridge)\n",
    "\n",
    "final_test_accuracy_ridge = accuracy(test_confusion_matrix_ridge)\n",
    "final_test_precision_ridge = precision(test_confusion_matrix_ridge)\n",
    "final_test_recall_ridge = recall(test_confusion_matrix_ridge)\n",
    "\n",
    "final_full_accuracy_ridge = accuracy(full_confusion_matrix_ridge)\n",
    "final_full_precision_ridge = precision(full_confusion_matrix_ridge)\n",
    "final_full_recall_ridge = recall(full_confusion_matrix_ridge)\n",
    "\n",
    "print('\\n Ridge full-Accuracy: %.6f' % final_full_accuracy_ridge)\n",
    "print(' Ridge full-Precision: %.6f' % final_full_precision_ridge)\n",
    "print(' Ridge full-Recall: %.6f' % final_full_recall_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold 1\n",
      "[0]\ttrain-logloss:0.685507\teval-logloss:0.685548\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-logloss:0.439211\teval-logloss:0.438961\n",
      "[100]\ttrain-logloss:0.321104\teval-logloss:0.321167\n",
      "[150]\ttrain-logloss:0.256851\teval-logloss:0.257696\n",
      "[200]\ttrain-logloss:0.21937\teval-logloss:0.221249\n",
      "[250]\ttrain-logloss:0.198041\teval-logloss:0.201109\n",
      "[300]\ttrain-logloss:0.183968\teval-logloss:0.188478\n",
      "[350]\ttrain-logloss:0.175379\teval-logloss:0.181201\n",
      "[400]\ttrain-logloss:0.16951\teval-logloss:0.176779\n",
      "[450]\ttrain-logloss:0.165116\teval-logloss:0.173973\n",
      "[500]\ttrain-logloss:0.161871\teval-logloss:0.171966\n",
      "[550]\ttrain-logloss:0.159499\teval-logloss:0.170799\n",
      "[600]\ttrain-logloss:0.157419\teval-logloss:0.170042\n",
      "[650]\ttrain-logloss:0.155745\teval-logloss:0.169549\n",
      "[700]\ttrain-logloss:0.154111\teval-logloss:0.169042\n",
      "[750]\ttrain-logloss:0.152798\teval-logloss:0.168672\n",
      "[800]\ttrain-logloss:0.151366\teval-logloss:0.1685\n",
      "[850]\ttrain-logloss:0.15013\teval-logloss:0.168222\n",
      "[900]\ttrain-logloss:0.148815\teval-logloss:0.167935\n",
      "[950]\ttrain-logloss:0.147537\teval-logloss:0.16781\n",
      "[1000]\ttrain-logloss:0.146159\teval-logloss:0.167676\n",
      "[1050]\ttrain-logloss:0.145017\teval-logloss:0.167587\n",
      "[1100]\ttrain-logloss:0.143946\teval-logloss:0.167306\n",
      "[1150]\ttrain-logloss:0.142688\teval-logloss:0.167114\n",
      "[1200]\ttrain-logloss:0.141539\teval-logloss:0.167082\n",
      "[1250]\ttrain-logloss:0.14037\teval-logloss:0.167115\n",
      "[1300]\ttrain-logloss:0.139199\teval-logloss:0.166975\n",
      "[1350]\ttrain-logloss:0.138099\teval-logloss:0.166939\n",
      "[1400]\ttrain-logloss:0.13698\teval-logloss:0.166795\n",
      "[1450]\ttrain-logloss:0.13595\teval-logloss:0.166811\n",
      "Stopping. Best iteration:\n",
      "[1427]\ttrain-logloss:0.136439\teval-logloss:0.16673\n",
      "\n",
      "\n",
      " Fold 2\n",
      "[0]\ttrain-logloss:0.685502\teval-logloss:0.685562\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-logloss:0.439065\teval-logloss:0.441643\n",
      "[100]\ttrain-logloss:0.320667\teval-logloss:0.325141\n",
      "[150]\ttrain-logloss:0.256122\teval-logloss:0.262347\n",
      "[200]\ttrain-logloss:0.218658\teval-logloss:0.226164\n",
      "[250]\ttrain-logloss:0.197494\teval-logloss:0.205964\n",
      "[300]\ttrain-logloss:0.183543\teval-logloss:0.192994\n",
      "[350]\ttrain-logloss:0.174993\teval-logloss:0.185413\n",
      "[400]\ttrain-logloss:0.16915\teval-logloss:0.180546\n",
      "[450]\ttrain-logloss:0.164792\teval-logloss:0.177323\n",
      "[500]\ttrain-logloss:0.161527\teval-logloss:0.175185\n",
      "[550]\ttrain-logloss:0.159032\teval-logloss:0.173854\n",
      "[600]\ttrain-logloss:0.157151\teval-logloss:0.173001\n",
      "[650]\ttrain-logloss:0.15548\teval-logloss:0.172435\n",
      "[700]\ttrain-logloss:0.154037\teval-logloss:0.172087\n",
      "[750]\ttrain-logloss:0.152669\teval-logloss:0.171552\n",
      "[800]\ttrain-logloss:0.151294\teval-logloss:0.171414\n",
      "[850]\ttrain-logloss:0.149947\teval-logloss:0.171253\n",
      "[900]\ttrain-logloss:0.148708\teval-logloss:0.171075\n",
      "[950]\ttrain-logloss:0.147447\teval-logloss:0.170843\n",
      "[1000]\ttrain-logloss:0.146137\teval-logloss:0.170841\n",
      "Stopping. Best iteration:\n",
      "[951]\ttrain-logloss:0.147438\teval-logloss:0.170837\n",
      "\n",
      "\n",
      " Fold 3\n",
      "[0]\ttrain-logloss:0.68549\teval-logloss:0.685491\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-logloss:0.438769\teval-logloss:0.440029\n",
      "[100]\ttrain-logloss:0.320661\teval-logloss:0.323447\n",
      "[150]\ttrain-logloss:0.256434\teval-logloss:0.260697\n",
      "[200]\ttrain-logloss:0.218996\teval-logloss:0.2246\n",
      "[250]\ttrain-logloss:0.197954\teval-logloss:0.204893\n",
      "[300]\ttrain-logloss:0.183928\teval-logloss:0.192604\n",
      "[350]\ttrain-logloss:0.175378\teval-logloss:0.185655\n",
      "[400]\ttrain-logloss:0.1695\teval-logloss:0.181164\n",
      "[450]\ttrain-logloss:0.165272\teval-logloss:0.17814\n",
      "[500]\ttrain-logloss:0.16212\teval-logloss:0.176182\n",
      "[550]\ttrain-logloss:0.159758\teval-logloss:0.175013\n",
      "[600]\ttrain-logloss:0.157781\teval-logloss:0.174171\n",
      "[650]\ttrain-logloss:0.156212\teval-logloss:0.173561\n",
      "[700]\ttrain-logloss:0.15466\teval-logloss:0.173044\n",
      "[750]\ttrain-logloss:0.153277\teval-logloss:0.172559\n",
      "[800]\ttrain-logloss:0.151898\teval-logloss:0.172215\n",
      "[850]\ttrain-logloss:0.15062\teval-logloss:0.171805\n",
      "[900]\ttrain-logloss:0.149242\teval-logloss:0.171573\n",
      "[950]\ttrain-logloss:0.148018\teval-logloss:0.171291\n",
      "[1000]\ttrain-logloss:0.146862\teval-logloss:0.171024\n",
      "[1050]\ttrain-logloss:0.145666\teval-logloss:0.170776\n",
      "[1100]\ttrain-logloss:0.144464\teval-logloss:0.170499\n",
      "[1150]\ttrain-logloss:0.143183\teval-logloss:0.170355\n",
      "[1200]\ttrain-logloss:0.142083\teval-logloss:0.170193\n",
      "[1250]\ttrain-logloss:0.140953\teval-logloss:0.170165\n",
      "[1300]\ttrain-logloss:0.139903\teval-logloss:0.170001\n",
      "[1350]\ttrain-logloss:0.138826\teval-logloss:0.169911\n",
      "[1400]\ttrain-logloss:0.137829\teval-logloss:0.169745\n",
      "[1450]\ttrain-logloss:0.136734\teval-logloss:0.169581\n",
      "[1500]\ttrain-logloss:0.135606\teval-logloss:0.169364\n",
      "[1550]\ttrain-logloss:0.13462\teval-logloss:0.169206\n",
      "[1600]\ttrain-logloss:0.133585\teval-logloss:0.169132\n",
      "[1650]\ttrain-logloss:0.132606\teval-logloss:0.169013\n",
      "[1700]\ttrain-logloss:0.131691\teval-logloss:0.168896\n",
      "[1750]\ttrain-logloss:0.130712\teval-logloss:0.168918\n",
      "Stopping. Best iteration:\n",
      "[1706]\ttrain-logloss:0.131564\teval-logloss:0.168851\n",
      "\n",
      "\n",
      " Fold 4\n",
      "[0]\ttrain-logloss:0.685471\teval-logloss:0.68563\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-logloss:0.438438\teval-logloss:0.443265\n",
      "[100]\ttrain-logloss:0.319944\teval-logloss:0.328047\n",
      "[150]\ttrain-logloss:0.255484\teval-logloss:0.266138\n",
      "[200]\ttrain-logloss:0.21795\teval-logloss:0.230817\n",
      "[250]\ttrain-logloss:0.19671\teval-logloss:0.211649\n",
      "[300]\ttrain-logloss:0.182726\teval-logloss:0.199685\n",
      "[350]\ttrain-logloss:0.17421\teval-logloss:0.192823\n",
      "[400]\ttrain-logloss:0.168385\teval-logloss:0.188608\n",
      "[450]\ttrain-logloss:0.164067\teval-logloss:0.185527\n",
      "[500]\ttrain-logloss:0.160886\teval-logloss:0.183711\n",
      "[550]\ttrain-logloss:0.158306\teval-logloss:0.182444\n",
      "[600]\ttrain-logloss:0.156438\teval-logloss:0.181725\n",
      "[650]\ttrain-logloss:0.154815\teval-logloss:0.181238\n",
      "[700]\ttrain-logloss:0.153271\teval-logloss:0.180951\n",
      "[750]\ttrain-logloss:0.151936\teval-logloss:0.180784\n",
      "[800]\ttrain-logloss:0.150448\teval-logloss:0.180709\n",
      "[850]\ttrain-logloss:0.149067\teval-logloss:0.180595\n",
      "[900]\ttrain-logloss:0.147686\teval-logloss:0.180369\n",
      "[950]\ttrain-logloss:0.146364\teval-logloss:0.180351\n",
      "Stopping. Best iteration:\n",
      "[913]\ttrain-logloss:0.147334\teval-logloss:0.18025\n",
      "\n",
      "\n",
      " Fold 5\n",
      "[0]\ttrain-logloss:0.685486\teval-logloss:0.685478\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-logloss:0.4392\teval-logloss:0.438622\n",
      "[100]\ttrain-logloss:0.321054\teval-logloss:0.320541\n",
      "[150]\ttrain-logloss:0.256816\teval-logloss:0.257125\n",
      "[200]\ttrain-logloss:0.219307\teval-logloss:0.220714\n",
      "[250]\ttrain-logloss:0.19832\teval-logloss:0.200761\n",
      "[300]\ttrain-logloss:0.18422\teval-logloss:0.187548\n",
      "[350]\ttrain-logloss:0.175722\teval-logloss:0.179983\n",
      "[400]\ttrain-logloss:0.169819\teval-logloss:0.174897\n",
      "[450]\ttrain-logloss:0.16554\teval-logloss:0.171634\n",
      "[500]\ttrain-logloss:0.162372\teval-logloss:0.169439\n",
      "[550]\ttrain-logloss:0.160015\teval-logloss:0.168181\n",
      "[600]\ttrain-logloss:0.158106\teval-logloss:0.167062\n",
      "[650]\ttrain-logloss:0.156444\teval-logloss:0.166253\n",
      "[700]\ttrain-logloss:0.154956\teval-logloss:0.16585\n",
      "[750]\ttrain-logloss:0.153632\teval-logloss:0.165469\n",
      "[800]\ttrain-logloss:0.152298\teval-logloss:0.165026\n",
      "[850]\ttrain-logloss:0.151007\teval-logloss:0.164753\n",
      "[900]\ttrain-logloss:0.149703\teval-logloss:0.164421\n",
      "[950]\ttrain-logloss:0.148356\teval-logloss:0.164101\n",
      "[1000]\ttrain-logloss:0.147082\teval-logloss:0.163734\n",
      "[1050]\ttrain-logloss:0.145933\teval-logloss:0.163536\n",
      "[1100]\ttrain-logloss:0.144673\teval-logloss:0.163398\n",
      "[1150]\ttrain-logloss:0.143561\teval-logloss:0.163296\n",
      "[1200]\ttrain-logloss:0.142364\teval-logloss:0.163186\n",
      "[1250]\ttrain-logloss:0.141273\teval-logloss:0.163092\n",
      "[1300]\ttrain-logloss:0.14026\teval-logloss:0.16283\n",
      "[1350]\ttrain-logloss:0.139253\teval-logloss:0.162703\n",
      "[1400]\ttrain-logloss:0.138256\teval-logloss:0.162634\n",
      "[1450]\ttrain-logloss:0.137115\teval-logloss:0.162509\n",
      "[1500]\ttrain-logloss:0.136008\teval-logloss:0.162383\n",
      "[1550]\ttrain-logloss:0.135013\teval-logloss:0.162336\n",
      "[1600]\ttrain-logloss:0.134076\teval-logloss:0.162254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1650]\ttrain-logloss:0.13305\teval-logloss:0.162165\n",
      "[1700]\ttrain-logloss:0.132109\teval-logloss:0.162161\n",
      "Stopping. Best iteration:\n",
      "[1690]\ttrain-logloss:0.132293\teval-logloss:0.162087\n",
      "\n",
      "\n",
      " Fold 6\n",
      "[0]\ttrain-logloss:0.685533\teval-logloss:0.685529\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-logloss:0.43751\teval-logloss:0.437848\n",
      "[100]\ttrain-logloss:0.319623\teval-logloss:0.320283\n",
      "[150]\ttrain-logloss:0.255765\teval-logloss:0.257142\n",
      "[200]\ttrain-logloss:0.219407\teval-logloss:0.222014\n",
      "[250]\ttrain-logloss:0.197423\teval-logloss:0.201443\n",
      "[300]\ttrain-logloss:0.18386\teval-logloss:0.189209\n",
      "[350]\ttrain-logloss:0.175179\teval-logloss:0.181533\n",
      "[400]\ttrain-logloss:0.169282\teval-logloss:0.176847\n",
      "[450]\ttrain-logloss:0.165258\teval-logloss:0.173821\n",
      "[500]\ttrain-logloss:0.16231\teval-logloss:0.171956\n",
      "[550]\ttrain-logloss:0.160038\teval-logloss:0.170644\n",
      "[600]\ttrain-logloss:0.15825\teval-logloss:0.169846\n",
      "[650]\ttrain-logloss:0.156677\teval-logloss:0.169302\n",
      "[700]\ttrain-logloss:0.155324\teval-logloss:0.168889\n",
      "[750]\ttrain-logloss:0.153696\teval-logloss:0.168647\n",
      "[800]\ttrain-logloss:0.152276\teval-logloss:0.168407\n",
      "[850]\ttrain-logloss:0.150941\teval-logloss:0.16817\n",
      "[900]\ttrain-logloss:0.149699\teval-logloss:0.168103\n",
      "[950]\ttrain-logloss:0.148384\teval-logloss:0.168099\n",
      "Stopping. Best iteration:\n",
      "[926]\ttrain-logloss:0.14907\teval-logloss:0.168043\n",
      "\n",
      "\n",
      " Fold 7\n",
      "[0]\ttrain-logloss:0.685505\teval-logloss:0.685613\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-logloss:0.437134\teval-logloss:0.440406\n",
      "[100]\ttrain-logloss:0.319062\teval-logloss:0.324725\n",
      "[150]\ttrain-logloss:0.25515\teval-logloss:0.262587\n",
      "[200]\ttrain-logloss:0.218731\teval-logloss:0.22794\n",
      "[250]\ttrain-logloss:0.196578\teval-logloss:0.20774\n",
      "[300]\ttrain-logloss:0.182989\teval-logloss:0.196027\n",
      "[350]\ttrain-logloss:0.174232\teval-logloss:0.189159\n",
      "[400]\ttrain-logloss:0.168364\teval-logloss:0.184997\n",
      "[450]\ttrain-logloss:0.164322\teval-logloss:0.182484\n",
      "[500]\ttrain-logloss:0.161251\teval-logloss:0.181074\n",
      "[550]\ttrain-logloss:0.158872\teval-logloss:0.18004\n",
      "[600]\ttrain-logloss:0.156956\teval-logloss:0.1795\n",
      "[650]\ttrain-logloss:0.15534\teval-logloss:0.179017\n",
      "[700]\ttrain-logloss:0.153907\teval-logloss:0.178658\n",
      "[750]\ttrain-logloss:0.152489\teval-logloss:0.178444\n",
      "[800]\ttrain-logloss:0.151009\teval-logloss:0.17841\n",
      "Stopping. Best iteration:\n",
      "[792]\ttrain-logloss:0.151214\teval-logloss:0.178344\n",
      "\n",
      "\n",
      " Fold 8\n",
      "[0]\ttrain-logloss:0.686285\teval-logloss:0.686291\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-logloss:0.437465\teval-logloss:0.438168\n",
      "[100]\ttrain-logloss:0.31886\teval-logloss:0.320509\n",
      "[150]\ttrain-logloss:0.25649\teval-logloss:0.259495\n",
      "[200]\ttrain-logloss:0.219884\teval-logloss:0.224027\n",
      "[250]\ttrain-logloss:0.198376\teval-logloss:0.203466\n",
      "[300]\ttrain-logloss:0.184046\teval-logloss:0.190276\n",
      "[350]\ttrain-logloss:0.175209\teval-logloss:0.182512\n",
      "[400]\ttrain-logloss:0.169344\teval-logloss:0.177717\n",
      "[450]\ttrain-logloss:0.165204\teval-logloss:0.174451\n",
      "[500]\ttrain-logloss:0.162059\teval-logloss:0.172436\n",
      "[550]\ttrain-logloss:0.159657\teval-logloss:0.170985\n",
      "[600]\ttrain-logloss:0.157684\teval-logloss:0.170094\n",
      "[650]\ttrain-logloss:0.156073\teval-logloss:0.169596\n",
      "[700]\ttrain-logloss:0.154595\teval-logloss:0.169169\n",
      "[750]\ttrain-logloss:0.153132\teval-logloss:0.168883\n",
      "[800]\ttrain-logloss:0.151786\teval-logloss:0.168764\n",
      "[850]\ttrain-logloss:0.150468\teval-logloss:0.168644\n",
      "[900]\ttrain-logloss:0.149148\teval-logloss:0.168494\n",
      "[950]\ttrain-logloss:0.147872\teval-logloss:0.168451\n",
      "[1000]\ttrain-logloss:0.146729\teval-logloss:0.168409\n",
      "[1050]\ttrain-logloss:0.145415\teval-logloss:0.168271\n",
      "Stopping. Best iteration:\n",
      "[1048]\ttrain-logloss:0.145457\teval-logloss:0.16825\n",
      "\n",
      "\n",
      " Fold 9\n",
      "[0]\ttrain-logloss:0.686206\teval-logloss:0.686303\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-logloss:0.436569\teval-logloss:0.442883\n",
      "[100]\ttrain-logloss:0.317542\teval-logloss:0.328496\n",
      "[150]\ttrain-logloss:0.25503\teval-logloss:0.269863\n",
      "[200]\ttrain-logloss:0.218242\teval-logloss:0.236055\n",
      "[250]\ttrain-logloss:0.196752\teval-logloss:0.216877\n",
      "[300]\ttrain-logloss:0.182596\teval-logloss:0.204498\n",
      "[350]\ttrain-logloss:0.173633\teval-logloss:0.196847\n",
      "[400]\ttrain-logloss:0.167804\teval-logloss:0.192346\n",
      "[450]\ttrain-logloss:0.163587\teval-logloss:0.189443\n",
      "[500]\ttrain-logloss:0.160516\teval-logloss:0.187631\n",
      "[550]\ttrain-logloss:0.158119\teval-logloss:0.186458\n",
      "[600]\ttrain-logloss:0.156407\teval-logloss:0.185841\n",
      "[650]\ttrain-logloss:0.154764\teval-logloss:0.185281\n",
      "[700]\ttrain-logloss:0.153291\teval-logloss:0.185137\n",
      "[750]\ttrain-logloss:0.152055\teval-logloss:0.185043\n",
      "[800]\ttrain-logloss:0.150691\teval-logloss:0.184745\n",
      "[850]\ttrain-logloss:0.149373\teval-logloss:0.184516\n",
      "[900]\ttrain-logloss:0.14803\teval-logloss:0.184339\n",
      "[950]\ttrain-logloss:0.146734\teval-logloss:0.184192\n",
      "[1000]\ttrain-logloss:0.145497\teval-logloss:0.184059\n",
      "[1050]\ttrain-logloss:0.144208\teval-logloss:0.184096\n",
      "Stopping. Best iteration:\n",
      "[1026]\ttrain-logloss:0.144809\teval-logloss:0.184003\n",
      "\n",
      "\n",
      " Fold 10\n",
      "[0]\ttrain-logloss:0.686237\teval-logloss:0.686293\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-logloss:0.436856\teval-logloss:0.440818\n",
      "[100]\ttrain-logloss:0.317994\teval-logloss:0.325164\n",
      "[150]\ttrain-logloss:0.255637\teval-logloss:0.265559\n",
      "[200]\ttrain-logloss:0.218927\teval-logloss:0.231245\n",
      "[250]\ttrain-logloss:0.197315\teval-logloss:0.211531\n",
      "[300]\ttrain-logloss:0.183071\teval-logloss:0.198549\n",
      "[350]\ttrain-logloss:0.174073\teval-logloss:0.190587\n",
      "[400]\ttrain-logloss:0.16817\teval-logloss:0.185802\n",
      "[450]\ttrain-logloss:0.164088\teval-logloss:0.18285\n",
      "[500]\ttrain-logloss:0.161031\teval-logloss:0.18107\n",
      "[550]\ttrain-logloss:0.158601\teval-logloss:0.179839\n",
      "[600]\ttrain-logloss:0.156632\teval-logloss:0.179036\n",
      "[650]\ttrain-logloss:0.154948\teval-logloss:0.178567\n",
      "[700]\ttrain-logloss:0.153467\teval-logloss:0.17815\n",
      "[750]\ttrain-logloss:0.152132\teval-logloss:0.17795\n",
      "[800]\ttrain-logloss:0.150638\teval-logloss:0.177582\n",
      "[850]\ttrain-logloss:0.149277\teval-logloss:0.177458\n",
      "[900]\ttrain-logloss:0.148014\teval-logloss:0.177171\n",
      "[950]\ttrain-logloss:0.146794\teval-logloss:0.177161\n",
      "[1000]\ttrain-logloss:0.145577\teval-logloss:0.177168\n",
      "Stopping. Best iteration:\n",
      "[963]\ttrain-logloss:0.146466\teval-logloss:0.17712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "def xgb_model(d_train, d_valid):\n",
    "    \n",
    "    params = {\n",
    "        'learning_rate': 0.01,\n",
    "        'n_estimators': 1000,\n",
    "        'max_depth': 5,\n",
    "        'min_child_weight': 1,\n",
    "        'gamma': 0,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'objective': 'binary:logistic',\n",
    "        'nthread': -1,\n",
    "        'scale_pos_weight': 1,\n",
    "        'seed': 27,\n",
    "        'eval_metric': 'logloss',\n",
    "        #'num_class': 1,\n",
    "        'silent': 1\n",
    "    }\n",
    "\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'eval')]\n",
    "\n",
    "    xgb_model = xgb.train(params,\n",
    "                          d_train,\n",
    "                          10000, # number of rounds\n",
    "                          watchlist,\n",
    "                          early_stopping_rounds = 50,\n",
    "                          verbose_eval=50\n",
    "                          )\n",
    "    return xgb_model\n",
    "\n",
    "n_folds = 10\n",
    "i = 0\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_folds, random_state=123, shuffle=True)\n",
    "\n",
    "for (train_index, test_index) in skf.split(X_train, y_train):\n",
    "    # cross-validation randomly splits train data into train and validation data\n",
    "    print('\\n Fold %d' % (i + 1))\n",
    "\n",
    "    X_train_cv, X_val_cv = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_cv, y_val_cv = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "    d_train = xgb.DMatrix(X_train_cv, label=y_train_cv)\n",
    "    d_valid = xgb.DMatrix(X_val_cv, label=y_val_cv)\n",
    "    d_train_full = xgb.DMatrix(X_train)\n",
    "    d_test = xgb.DMatrix(X_test)\n",
    "    d_full = xgb.DMatrix(X_full)\n",
    "\n",
    "    # declare your model\n",
    "    model = xgb_model(d_train, d_valid)\n",
    "    \n",
    "    # predict the train, test and full data and add it to the other predictions\n",
    "    train_pred = model.predict(d_train_full, ntree_limit=model.best_ntree_limit)  \n",
    "    test_pred = model.predict(d_test, ntree_limit=model.best_ntree_limit)\n",
    "    full_pred = model.predict(d_full, ntree_limit=model.best_ntree_limit)\n",
    "    \n",
    "    \n",
    "    \n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Average XGB accuracy: 0.927746\n",
      "\n",
      " Average XGB precision: 0.720456\n",
      "\n",
      " Average XGB recall: 0.585991\n"
     ]
    }
   ],
   "source": [
    "# divide predictions and CV-sum by number of folds to get mean of all folds\n",
    "final_train_pred_xgb = model.predict(d_train_full, ntree_limit=model.best_ntree_limit) \n",
    "final_test_pred_xgb = model.predict(d_test, ntree_limit=model.best_ntree_limit)\n",
    "final_full_pred_xgb = model.predict(d_full, ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "train_confusion_matrix_xgb = confusion_matrix(y_train, np.around(final_train_pred_xgb).astype(int))\n",
    "test_confusion_matrix_xgb = confusion_matrix(y_test, np.around(final_test_pred_xgb).astype(int))\n",
    "full_confusion_matrix_xgb = confusion_matrix(y_full, np.around(final_full_pred_xgb).astype(int))\n",
    "\n",
    "final_train_accuracy_xgb = accuracy(train_confusion_matrix_xgb)\n",
    "final_train_precision_xgb = precision(train_confusion_matrix_xgb)\n",
    "final_train_recall_xgb = recall(train_confusion_matrix_xgb)\n",
    "\n",
    "final_test_accuracy_xgb = accuracy(test_confusion_matrix_xgb)\n",
    "final_test_precision_xgb = precision(test_confusion_matrix_xgb)\n",
    "final_test_recall_xgb = recall(test_confusion_matrix_xgb)\n",
    "\n",
    "final_full_accuracy_xgb = accuracy(full_confusion_matrix_xgb)\n",
    "final_full_precision_xgb = precision(full_confusion_matrix_xgb)\n",
    "final_full_recall_xgb = recall(full_confusion_matrix_xgb)\n",
    "\n",
    "print('\\n Average XGB accuracy: %.6f' % final_full_accuracy_xgb)\n",
    "print('\\n Average XGB precision: %.6f' % final_full_precision_xgb)\n",
    "print('\\n Average XGB recall: %.6f' % final_full_recall_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
